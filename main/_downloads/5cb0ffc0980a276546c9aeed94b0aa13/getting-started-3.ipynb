{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b3U8UxLPfIi"
      },
      "source": [
        "\n",
        "# Get started with data collection and storage\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensordict torchrl"
      ],
      "metadata": {
        "id": "uHaS4B2CPhDm",
        "outputId": "78a2e0e8-5fd9-475a-92e8-590fddb6c471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensordict\n",
            "  Downloading tensordict-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.9.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from tensordict) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensordict) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from tensordict) (3.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensordict) (25.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from tensordict) (8.7.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from tensordict) (3.11.2)\n",
            "Collecting pyvers<0.2.0,>=0.1.0 (from tensordict)\n",
            "  Downloading pyvers-0.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict) (3.4.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->tensordict) (3.23.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->tensordict) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->tensordict) (3.0.2)\n",
            "Downloading tensordict-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (430 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.2/430.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchrl-0.9.2-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvers-0.1.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyvers, tensordict, torchrl\n",
            "Successfully installed pyvers-0.1.0 tensordict-0.9.1 torchrl-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W0nJW54cPfIi"
      },
      "outputs": [],
      "source": [
        "import tempfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6BDMnEoPfIj"
      },
      "source": [
        "There is no learning without data. In supervised learning, users are\n",
        "accustomed to using :class:`~torch.utils.data.DataLoader` and the like\n",
        "to integrate data in their training loop.\n",
        "Dataloaders are iterable objects that provide you with the data that you will\n",
        "be using to train your model.\n",
        "\n",
        "TorchRL approaches the problem of dataloading in a similar manner, although\n",
        "it is surprisingly unique in the ecosystem of RL libraries. TorchRL's\n",
        "dataloaders are referred to as ``DataCollectors``. Most of the time,\n",
        "data collection does not stop at the collection of raw data,\n",
        "as the data needs to be stored temporarily in a buffer\n",
        "(or equivalent structure for on-policy algorithms) before being consumed\n",
        "by the `loss module <gs_optim>`. This tutorial will explore\n",
        "these two classes.\n",
        "\n",
        "## Data collectors\n",
        "\n",
        "\n",
        "\n",
        "The primary data collector discussed here is the\n",
        ":class:`~torchrl.collectors.SyncDataCollector`, which is the focus of this\n",
        "documentation. At a fundamental level, a collector is a straightforward\n",
        "class responsible for executing your policy within the environment,\n",
        "resetting the environment when necessary, and providing batches of a\n",
        "predefined size. Unlike the :meth:`~torchrl.envs.EnvBase.rollout` method\n",
        "demonstrated in `the env tutorial <gs_env_ted>`, collectors do not\n",
        "reset between consecutive batches of data. Consequently, two successive\n",
        "batches of data may contain elements from the same trajectory.\n",
        "\n",
        "The basic arguments you need to pass to your collector are the size of the\n",
        "batches you want to collect (``frames_per_batch``), the length (possibly\n",
        "infinite) of the iterator, the policy and the environment. For simplicity,\n",
        "we will use a dummy, random policy in this example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y5hRoq5rPfIj",
        "outputId": "baa152f7-6a1a-4a9d-f8f2-a1bbb87cffa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:151: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.envs import GymEnv\n",
        "from torchrl.envs.utils import RandomPolicy\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "env = GymEnv(\"CartPole-v1\")\n",
        "env.set_seed(0)\n",
        "\n",
        "policy = RandomPolicy(env.action_spec)\n",
        "collector = SyncDataCollector(env, policy, frames_per_batch=200, total_frames=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG-YygHuPfIj"
      },
      "source": [
        "We now expect that our collector will deliver batches of size ``200`` no\n",
        "matter what happens during collection. In other words, we may have multiple\n",
        "trajectories in this batch! The ``total_frames`` indicates how long the\n",
        "collector should be. A value of ``-1`` will produce a never\n",
        "ending collector.\n",
        "\n",
        "Let's iterate over the collector to get a sense\n",
        "of what this data looks like:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VWyhGiAcPfIj",
        "outputId": "4414a4bd-cad4-4e18-95bb-26d36d9e463a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        collector: TensorDict(\n",
            "            fields={\n",
            "                traj_ids: Tensor(shape=torch.Size([200]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
            "            batch_size=torch.Size([200]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([200, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([200]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([200, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([200]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "for data in collector:\n",
        "    print(data)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHw8yLdZPfIj"
      },
      "source": [
        "As you can see, our data is augmented with some collector-specific metadata\n",
        "grouped in a ``\"collector\"`` sub-tensordict that we did not see during\n",
        "`environment rollouts <gs_env_ted_rollout>`. This is useful to keep track of\n",
        "the trajectory ids. In the following list, each item marks the trajectory\n",
        "number the corresponding transition belongs to:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p4CmltOOPfIj",
        "outputId": "35be6e3c-fabf-4a3c-93df-19f3e0711f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
            "        6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
            "        7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
            "        9, 9, 9, 9, 9, 9, 9, 9])\n"
          ]
        }
      ],
      "source": [
        "print(data[\"collector\", \"traj_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvDLyhhDPfIj"
      },
      "source": [
        "Data collectors are very useful when it comes to coding state-of-the-art\n",
        "algorithms, as performance is usually measured by the capability of a\n",
        "specific technique to solve a problem in a given number of interactions with\n",
        "the environment (the ``total_frames`` argument in the collector).\n",
        "For this reason, most training loops in our examples look like this:\n",
        "\n",
        "  ..code - block::Python\n",
        "\n",
        "    >>> for data in collector:\n",
        "    ...     # your algorithm here\n",
        "\n",
        "\n",
        "## Replay Buffers\n",
        "\n",
        "\n",
        "Now that we have explored how to collect data, we would like to know how to\n",
        "store it. In RL, the typical setting is that the data is collected, stored\n",
        "temporarily and cleared after a little while given some heuristic:\n",
        "first-in first-out or other. A typical pseudo-code would look like this:\n",
        "\n",
        "..code - block::Python\n",
        "\n",
        "  >>> for data in collector:\n",
        "  ...     storage.store(data)\n",
        "  ...     for i in range(n_optim):\n",
        "  ...         sample = storage.sample()\n",
        "  ...         loss_val = loss_fn(sample)\n",
        "  ...         loss_val.backward()\n",
        "  ...         optim.step() # etc\n",
        "\n",
        "The parent class that stores the data in TorchRL\n",
        "is referred to as :class:`~torchrl.data.ReplayBuffer`. TorchRL's replay\n",
        "buffers are composable: you can edit the storage type, their sampling\n",
        "technique, the writing heuristic or the transforms applied to them. We will\n",
        "leave the fancy stuff for a dedicated in-depth tutorial. The generic replay\n",
        "buffer only needs to know what storage it has to use. In general, we\n",
        "recommend a :class:`~torchrl.data.TensorStorage` subclass, which will work\n",
        "fine in most cases. We'll be using\n",
        ":class:`~torchrl.data.replay_buffers.LazyMemmapStorage`\n",
        "in this tutorial, which enjoys two nice properties: first, being \"lazy\",\n",
        "you don't  need to explicitly tell it what your data looks like in advance.\n",
        "Second, it uses :class:`~tensordict.MemoryMappedTensor` as a backend to save\n",
        "your data on disk in an efficient way. The only thing you need to know is\n",
        "how big you want your buffer to be.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uwR51Cr4PfIk"
      },
      "outputs": [],
      "source": [
        "from torchrl.data.replay_buffers import LazyMemmapStorage, ReplayBuffer\n",
        "\n",
        "buffer_scratch_dir = tempfile.TemporaryDirectory().name\n",
        "\n",
        "buffer = ReplayBuffer(\n",
        "    storage=LazyMemmapStorage(max_size=1000, scratch_dir=buffer_scratch_dir)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HxBgU_GPfIk"
      },
      "source": [
        "Populating the buffer can be done via the\n",
        ":meth:`~torchrl.data.ReplayBuffer.add` (single element) or\n",
        ":meth:`~torchrl.data.ReplayBuffer.extend` (multiple elements) methods. Using\n",
        "the data we just collected, we initialize and populate the buffer in one go:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iz4pbORDPfIk"
      },
      "outputs": [],
      "source": [
        "indices = buffer.extend(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL44livQPfIk"
      },
      "source": [
        "We can check that the buffer now has the same number of elements as what\n",
        "we got from the collector:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M7A2XxJPPfIk"
      },
      "outputs": [],
      "source": [
        "assert len(buffer) == collector.frames_per_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf3SdC0LPfIk"
      },
      "source": [
        "The only thing left to know is how to gather data from the buffer.\n",
        "Naturally, this relies on the :meth:`~torchrl.data.ReplayBuffer.sample`\n",
        "method. Because we did not specify that sampling had to be done without\n",
        "repetitions, it is not guaranteed that the samples gathered from our buffer\n",
        "will be unique:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xH3OMfrPPfIk",
        "outputId": "2504253c-41e8-4260-a961-06361ab87c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([30, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        collector: TensorDict(\n",
            "            fields={\n",
            "                traj_ids: Tensor(shape=torch.Size([30]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
            "            batch_size=torch.Size([30]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([30]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([30]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "sample = buffer.sample(batch_size=30)\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6s2Y5PPfIk"
      },
      "source": [
        "Again, our sample looks exactly the same as the data we gathered from the\n",
        "collector!\n",
        "\n",
        "## Next steps\n",
        "\n",
        "- You can have look at other multiprocessed\n",
        "  collectors such as :class:`~torchrl.collectors.collectors.MultiSyncDataCollector` or\n",
        "  :class:`~torchrl.collectors.collectors.MultiaSyncDataCollector`.\n",
        "- TorchRL also offers distributed collectors if you have multiple nodes to\n",
        "  use for inference. Check them out in the\n",
        "  `API reference <ref_collectors>`.\n",
        "- Check the dedicated `Replay Buffer tutorial <rb_tuto>` to know\n",
        "  more about the options you have when building a buffer, or the\n",
        "  `API reference <ref_data>` which covers all the features in\n",
        "  details. Replay buffers have countless features such as multithreaded\n",
        "  sampling, prioritized experience replay, and many more...\n",
        "- We left out the capacity of replay buffers to be iterated over for\n",
        "  simplicity. Try it out for yourself: build a buffer and indicate its\n",
        "  batch-size in the constructor, then try to iterate over it. This is\n",
        "  equivalent to calling ``rb.sample()`` within a loop!\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}